<<<<<<< HEAD
# LangChain Research Agent

An autonomous research agent built with LangChain, LangGraph, FastAPI, Google Docs, and n8n integration. Automatically searches, synthesizes, and generates comprehensive research reports with citations.

## ðŸš€ Features

- **Autonomous Research**: Automated web search, content extraction, and synthesis
- **LangGraph Workflow**: Modular, stateful research pipeline with error handling
- **Google Docs Integration**: Automatic report generation in Google Docs
- **n8n Automation**: Workflow automation for notifications and storage
- **RESTful API**: FastAPI-based API with async support
- **Multi-user Support**: Handle multiple concurrent research requests
- **Citation Management**: Automatic citation generation in APA format
- **Monitoring**: LangSmith integration for workflow observability

## ðŸ“‹ Prerequisites

- Python 3.9+
- OpenAI API key
- Google Cloud Project with Docs & Drive API enabled
- n8n instance (optional but recommended)
- LangSmith account (optional, for monitoring)

## ðŸ› ï¸ Installation

### 1. Clone and Setup Environment

```bash
# Clone repository
git clone <your-repo-url>
cd langchain-research-agent

# Create virtual environment
python -m venv venv

# Activate virtual environment
# On Windows:
venv\Scripts\activate
# On Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configure Environment Variables

```bash
# Copy example env file
cp .env.example .env

# Edit .env with your credentials
nano .env  # or use your preferred editor
```

Required environment variables:
- `OPENAI_API_KEY`: Your OpenAI API key
- `GOOGLE_APPLICATION_CREDENTIALS`: Path to Google service account JSON
- `N8N_WEBHOOK_URL`: Your n8n webhook URL (optional)
- `LANGCHAIN_API_KEY`: LangSmith API key (optional)

### 3. Setup Google Cloud Credentials

1. Create a Google Cloud Project
2. Enable Google Docs API and Google Drive API
3. Create a service account
4. Download the JSON key file
5. Set path in `.env`: `GOOGLE_APPLICATION_CREDENTIALS=path/to/credentials.json`
6. Share your Google Drive folder with the service account email

### 4. Setup n8n Workflow (Optional)

1. Create a new workflow in n8n
2. Add a Webhook node as trigger
3. Add Google Sheets/Email/Slack nodes for notifications
4. Copy webhook URL to `.env`

## ðŸš€ Running the Application

### Development Mode

```bash
# Run with uvicorn
python app/main.py

# Or use uvicorn directly
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### Production Mode

```bash
# Using gunicorn with uvicorn workers
gunicorn app.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --timeout 300
```

## ðŸ“¡ API Endpoints

### Create Research Job

```bash
POST /api/v1/research
```

Request body:
```json
{
  "query": "What are the latest developments in quantum computing?",
  "user_id": "user123",
  "max_results": 10,
  "include_citations": true
}
```

Response:
```json
{
  "job_id": "abc-123-def",
  "status": "pending",
  "query": "What are the latest developments in quantum computing?",
  "created_at": "2025-01-28T10:00:00"
}
```

### Get Job Status

```bash
GET /api/v1/research/{job_id}
```

### Check Health

```bash
GET /api/v1/health
```

### List All Jobs

```bash
GET /api/v1/jobs?limit=10&offset=0
```

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI   â”‚
â”‚     API     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        LangGraph Workflow           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Query Intake                    â”‚
â”‚  2. Web Search (DuckDuckGo)         â”‚
â”‚  3. Content Filter (Relevance)      â”‚
â”‚  4. Content Extraction (Scraping)   â”‚
â”‚  5. Synthesizer (LLM)               â”‚
â”‚  6. Citation Handler                â”‚
â”‚  7. Report Generator                â”‚
â”‚  8. Error Handler                   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google Docs    â”‚     â”‚     n8n      â”‚
â”‚   Integration   â”‚     â”‚   Workflow   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“ Project Structure

```
langchain-research-agent/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic models
â”‚   â”œâ”€â”€ research_agent/
â”‚   â”‚   â”œâ”€â”€ graph.py            # LangGraph workflow
â”‚   â”‚   â”œâ”€â”€ nodes.py            # Workflow nodes
â”‚   â”‚   â”œâ”€â”€ state.py            # State management
â”‚   â”‚   â””â”€â”€ tools.py            # Research tools
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ google_docs.py      # Google Docs integration
â”‚   â”‚   â”œâ”€â”€ n8n_client.py       # n8n client
â”‚   â”‚   â””â”€â”€ llm_service.py      # LLM wrapper
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ logger.py           # Logging
â”‚   â”‚   â””â”€â”€ error_handlers.py  # Error handling
â”‚   â””â”€â”€ api/
â”‚       â””â”€â”€ routes.py           # API routes
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_api.py            # API tests
â”œâ”€â”€ logs/                       # Application logs
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ requirements.txt            # Dependencies
â””â”€â”€ README.md                   # This file
```

## ðŸ§ª Testing

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app tests/

# Run specific test file
pytest tests/test_api.py -v
```

## ðŸš¢ Deployment

### Railway

1. Create new project on Railway
2. Connect GitHub repository
3. Add environment variables
4. Deploy automatically

### Vercel

1. Install Vercel CLI: `npm i -g vercel`
2. Create `vercel.json`:
```json
{
  "builds": [
    {
      "src": "app/main.py",
      "use": "@vercel/python"
    }
  ],
  "routes": [
    {
      "src": "/(.*)",
      "dest": "app/main.py"
    }
  ]
}
```
3. Deploy: `vercel --prod`

### Google Cloud Platform

```bash
# Build and deploy to Cloud Run
gcloud run deploy research-agent \
  --source . \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

## ðŸ“Š Monitoring

### LangSmith

View workflow traces in LangSmith dashboard:
1. Go to https://smith.langchain.com
2. Select your project
3. View traces for each research job

### Application Logs

```bash
# View logs
tail -f logs/app.log

# View specific job logs
grep "job_id" logs/app.log
```

## ðŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `OPENAI_API_KEY` | OpenAI API key | Yes |
| `OPENAI_MODEL` | Model name (e.g., gpt-4-turbo-preview) | No |
| `GOOGLE_APPLICATION_CREDENTIALS` | Path to Google service account JSON | Yes |
| `N8N_WEBHOOK_URL` | n8n webhook URL | No |
| `LANGCHAIN_API_KEY` | LangSmith API key | No |
| `MAX_SEARCH_RESULTS` | Maximum search results | No |
| `MAX_CONTENT_LENGTH` | Max content length per page | No |

## ðŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open Pull Request

## ðŸ“ License

MIT License - see LICENSE file for details

## ðŸ†˜ Troubleshooting

### Common Issues

**Issue**: Google Docs API authentication fails
- **Solution**: Verify service account JSON path and permissions

**Issue**: Search returns no results
- **Solution**: Check internet connectivity and DuckDuckGo availability

**Issue**: LangSmith traces not appearing
- **Solution**: Verify `LANGCHAIN_API_KEY` and `LANGCHAIN_TRACING_V2=true`

**Issue**: n8n webhook timeout
- **Solution**: Increase timeout in `app/services/n8n_client.py`

## ðŸ“ž Support

For issues and questions:
- Open an issue on GitHub
- Check documentation at `/docs` endpoint
- Review logs in `logs/app.log`

## ðŸŽ¯ Roadmap

- [ ] Add database persistence (PostgreSQL/MongoDB)
- [ ] Implement rate limiting and authentication
- [ ] Add React frontend dashboard
- [ ] Support for multiple LLM providers
- [ ] Advanced citation formats (MLA, Chicago)
- [ ] PDF report generation
- [ ] Collaborative research features
- [ ] Advanced search filters and ranking

---

Built with â¤ï¸ using LangChain, FastAPI, and modern Python tools
=======
# Research-Agent-with-Automated-Report-Generation-and-Google-Docs-Workflow
>>>>>>> 939978c77287c2d63307e4e6c25a07e18c47dc55
